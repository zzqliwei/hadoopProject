3台虚拟机 
系统为：CentOS 6.8 64位

———————————————————————————————————————————————————————————————————————
hadoop安装
☛ 修改机器名称 
vi /etc/sysconfig/network 修改后需要重启虚拟机
HOSTNAME=master
HOSTNAME=slave1
HOSTNAME=slave2

☛ 修改/etc/hosts文件 这个文件是ip地址及其对应的主机名文件，使的ip与主机名的对应关系
vi /etc/hosts，类似于如下：
129.23.2.23 master
129.23.2.24 slave1
129.23.2.25 slave2
注意：在阿里云上部署的话这些ip需要是私有ip

☛ master配置SSH免密码登陆slave
保证每台机器中所在用户的根目录下包含掩藏文件.ssh，如果没有的话则需要创建一个
生成密钥： ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
将id_dsa.pub（公钥）追加到授权的key中： cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
将认证文件复制到其它节点上：scp ~/.ssh/authorized_keys slave1@192.168.1.241:~/.ssh/
在每一个节点修改文件目录权限， chmod 700 ~/.ssh chmod 600 ~/.ssh/ authorized_keys
ssh slave1试试，第一次连接需要输入yes确认即可，如果不需要密码就能登陆成功的话，表明这步设置成功

☛ 各个节点安装jdk
下载jdk到~/java目录，下载地址：
 http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
我用的是最新的java8
解压jdk tar包： tar –xvf jdk-8u144-linux-x64.tar
修改环境变量
cd ~
vi .bash_profile
export JAVA_HOME=/home/hadoop-twq/java/jdk1.8.0_144
PATH=$PATH:$HOME/bin:$JAVA_HOME/bin
source .bash_profile
java -version看看是否装成功了

☛ hadoop安装
下载 Hadoop， http://hadoop.apache.org/releases.html
 hadoop-2.6.5.tar 这个是我目前用的版本, 将这个tar包放到master上面的hadoop-twq用户的根目录下
解压hadoop-2.6.5 tar： tar –xvf hadoop-2.6.5.tar

☛ 修改hadoop配置，配置文件都在${HADOOP_HOME}/etc/hadoop下
修改core-site.xml
<configuration>
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://master:9999</value>
</property>
</configuration>
修改hdfs-site.xml
<configuration>
        <property>
                <name>dfs.replication</name>  #值不应大于datanode数量
                <value>1</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name> #设置分布式文件系统存放于/home/hadooper/hadoop/dfs 的本地目录
                <value>/home/hadoop-twq/hadoop/dfs/name</value>
                <description>  </description>
        </property>
 
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/home/hadoop-twq/hadoop/dfs/data</value>
                <description> </description>
        </property>
 
        <property>
                <name>dfs.webhdfs.enabled</name>
                <value>true</value>
        </property>
</configuration>
修改yarn-site.xml
	<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>master:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>master:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>master:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address</name>
        <value>master:8033</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:8088</value>
    </property>
    <property>
            <name>yarn.nodemanager.pmem-check-enabled</name>
            <value>false</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
            <value>false</value>
    </property>
修改slaves，在slaves文件中写入如下内容
slave1
slave2
修改hadoop-env.sh
在hadoop-env.sh中添加JAVA_HOME： export JAVA_HOME=/home/hadoop-twq/java/jdk1.8.0_144

☛ 创建nameNode和dataNode需要的文件目录
mkdir -p /home/hadoop-twq/hadoop/dfs/name
mkdir -p /home/hadoop-twq/hadoop/dfs/data

☛ 将master上配置好的hadoop分发到每一个slave上
scp -r hadoop hadoop-twq@slave1:~
scp -r hadoop hadoop-twq@slave2:~

scp -r hadoop-2.6.5 hadoop-twq@slave1:~
scp -r hadoop-2.6.5 hadoop-twq@slave2:~

在master上添加环境变量
       export HADOOP_HOME=/home/hadoop-twq/hadoop-2.6.5
       PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

☛ 运行hadoop
格式化： hdfs namenode –format
启动hdfs: 运行start-dfs.sh
http://master:50070看下是否部署成功
停止hdfs: 运行stop-dfs.sh

☛ 启动yarn: start-yarn.sh
http://master:8088/cluster访问这个url，查看yarn是否正常工作
停止yarn: stop-yarn.sh

———————————————————————————————————————————————————————————————————————
spark安装
☛ 安装scala
下载 http://www.scala-lang.org/download/2.11.8.html 版本为2.11.8，放到每一个节点上~/java，然后用tar -xf解压
配置环境变量，cd ~;  vi .bash_profile
export SCALA_HOME=/home/hadoop-twq/java/scala-2.11.8
PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SCALA_HOME/bin
source .bash_profile

☛ 安装spark

下载 http://spark.apache.org/downloads.html ,然后放到master上面的机器节点的根目录下：
版本为spark-2.2.0-bin-hadoop2.6.tgz
解压 tar -xf spark-2.2.0-bin-hadoop2.6.tgz

配置slaves
cd spark-2.2.0-bin-hadoop2.6/conf
cp slaves.template slaves
vi slaves,写入如下内容
slave1
slave2

配置spark-env.sh
cp spark-env.sh.template spark-env.sh
vi spark-env.sh写入如下内容
export JAVA_HOME=/home/hadoop-twq/java/jdk1.8.0_144

将配置好的spark拷贝到slave1和slave2节点上：
scp -r spark-2.2.0-bin-hadoop2.6 hadoop-twq@slave1:~
scp -r spark-2.2.0-bin-hadoop2.6 hadoop-twq@slave2:~

在master上配置环境变量：
cd ～
vi .bash_profile
export SPARK_HOME=/home/hadoop-twq/spark-2.2.0-bin-hadoop2.6
source .bash_profile

启动
cd ../sbin
./start-all.sh
http://47.92.157.11:7077/ 查看是否成功

使用spark-shell —master spark://master:7077测试spark代码

——————————————————————————————————————————————————————————————————————
本地开发环境

1: 安装java

2: 安装scala

3: 下载maven软件 http://maven.apache.org/download.cgi 并解压安装

4: 下载idea软件 https://www.jetbrains.com/idea/ 并安装并在settings中配置maven

———————————————————————————————————————————————————————————————————————
Spark源码环境搭建

1: 下载git客户端软件 https://git-scm.com

2: 在终端执行 git clone https://github.com/apache/spark.git 下载spark源代码

3: 将spark源代码导入到idea软件中，将spark分支切到branch-2.2

